好的。我把“Anthropic Messages API → OpenAI 风格后端（建议用 Chat Completions，也顺带标注 Responses 的差异）”需要实现的完整映射规约整理成一份可直接照着写转换器的清单。按“请求→历史与工具→多模态→采样与停止→流式→响应→错误与用量→边角差异→验收清单”的顺序展开。全程不用表格与示例代码，仅给出明确的字段与步骤规则。

目标与前提
前端客户端：按 Anthropic /v1/messages 形状发请求、收响应（含 SSE 事件）。

你的服务：把该请求转译为 OpenAI 后端（首选 /v1/chat/completions；若你用 /v1/responses，我单独标注差异），再把响应回译成 Anthropic 形状与事件。

文档基准：Anthropic 官方 Messages/Streaming/Stop reasons/Errors 与工具使用文档；OpenAI 官方 Chat Completions/Function (Tool) calling/Streaming/Responses 文档。
Anthropic
+3
Anthropic
+3
Anthropic
+3
 
OpenAI Platform
+3
OpenAI Platform
+3
OpenAI Platform
+3

1) HTTP 与头部适配
入站（来自 Claude Code）：

必带 anthropic-version，你服务器接受但不向后传；鉴权用 x-api-key。
Anthropic
+1

出站（到 OpenAI）：

设置 Authorization: Bearer <OPENAI_KEY>，Content-Type: application/json。

若走 Responses API，某些字段名不同（见第 4/6 节）。

流式（SSE）信道：

Anthropic：命名事件（message_start → content_block_* → message_delta → message_stop；可穿插 ping / error）。
Anthropic

OpenAI Chat Completions：无事件名，一行行 data: {chunk}，以 data: [DONE] 结束。
OpenAI Platform

你要把 OpenAI 的增量重放成 Anthropic 的事件序列（详见第 5 节）。

2) 顶层请求字段映射（Anthropic → OpenAI）
按以下规则构造 OpenAI 请求体：

model：做模型名映射表；Anthropic 的 “claude-*” 必须改成 OpenAI 的可用模型名。

system：Anthropic 是顶层字段（字符串或 content[]）。OpenAI 需要把它提升为首条 {"role":"system","content":...} 消息（若是 content[]，把文本拼接或逐段转到 system 的 content）。
Anthropic

messages：逐条转换（详见第 3 节“历史与工具块”）。
Anthropic

max_tokens：Chat Completions 也叫 max_tokens（同名可直传）。Responses API 则是 max_output_tokens。
OpenAI Platform

采样：temperature、top_p 可直传；top_k 在 OpenAI 无对应，应当丢弃。
Anthropic

自定义停：stop_sequences（数组）→ OpenAI 的 stop（数组）。
Anthropic

用户标识：metadata.user_id（若存在）→ OpenAI 的 user（可选）。
Anthropic

工具定义：把 tools[] 的 name/description/input_schema 改造为 OpenAI 的
tools: [{type:"function", function:{name, description, parameters: <input_schema>}}]。
Anthropic
OpenAI Platform

工具选择：

Anthropic tool_choice.type 映射："auto"→"auto"；"none"→"none"；"tool"（带 name）→ {"type":"function","function":{"name":<name>}}；"any" 建议也映射为 "auto"（OpenAI 无 “any”）。

disable_parallel_tool_use: true → Chat Completions 的 parallel_tool_calls: false（若不传则默认允许并行）。
Anthropic
+1

其他仅 Anthropic 的字段（如 thinking, service_tier, mcp_servers, container）：不要转传至 OpenAI；保留于你侧或忽略即可。
Anthropic

3) 历史与“工具消息”映射（最易踩坑）
A. 文本与多模态内容块（不含工具）
Anthropic 每条 message 的 content 可能是：

字符串（等价于 1 个 {"type":"text"} 块）；或

数组（混合 text、image 等块）。
Anthropic

向 OpenAI（Chat Completions）转换时：

text 块 → {"type":"text","text":...}（也可直接并入字符串，但为兼容多模态建议保持数组形）。

image 块：读取其 source：

type:"base64"：组装 Data URL（data:<media_type>;base64,<data>），做成 {"type":"image_url","image_url":{"url":<data-URL>}}。

有 URL 的情况：{"type":"image_url","image_url":{"url":<url>}}。

注意 OpenAI 仅在user 消息支持 image_url；不同模型对 image_url 结构的严格度不同，应按官方格式传入 对象 而非字符串。
Microsoft Learn
OpenAI Community
+1

B. 工具调用回放（核心）
Anthropic 在消息内容块里表达工具交互：

assistant 可能包含一个或多个 {"type":"tool_use","id", "name", "input"}；

之后你把工具结果作为下一条 user 消息里的 {"type":"tool_result","tool_use_id", "content": ...} 传回。
Anthropic

向 OpenAI 映射规则：

assistant 中的每个 tool_use → 同一轮 assistant 的 tool_calls[] 里新增一项；保持一一对应：

function.name = tool_use.name；

function.arguments = JSON.stringify(tool_use.input)；

生成 tool_call.id 并建立映射表：tool_use.id ↔ tool_call.id（供下一步使用）。
OpenAI Platform

tool_result（来自 Anthropic 的 user 消息 content 块）→ 单独的 OpenAI 消息：

role:"tool"，tool_call_id = 上一步映射到的 id；

content = 文本或 JSON 串（OpenAI 要求必须紧随其对应的 assistant 工具调用之后）。
Portkey
GitHub

顺序保证：必须是 assistant(tool_calls) 在前，tool 在后；否则 OpenAI 会报 “messages with role 'tool' must be a response to a preceding message with 'tool_calls'”。
Portkey

4) 采样、停止与其它控制项
temperature、top_p：可直传。top_k：OpenAI 不支持，丢弃。
Anthropic

stop_sequences[]：改名为 stop[]；语义等价。
Anthropic

max_tokens：Chat Completions 同名；Responses 用 max_output_tokens。
OpenAI Platform

tool_choice 已在第 2 节说明。

5) 流式转译（SSE → SSE）
当 Anthropic 请求里 stream: true 时，你需要把 OpenAI 的流即刻转成 Anthropic 事件：

事件骨架（无工具时）：

立刻发 event: message_start，其 message.content 空数组。

再发 event: content_block_start（index:0,content_block:{type:"text",text:""}）。

对 OpenAI 每个文本增量，发 event: content_block_delta，delta:{type:"text_delta", text:<chunk>}。

OpenAI 结束帧（[DONE]）到来时：先发 content_block_stop，再发一次 message_delta（可带累计 usage 与 stop_reason，见下），最后 message_stop。
Anthropic
OpenAI Platform

带工具流式：

OpenAI 会在增量里流出 tool_calls 的 function.name / arguments。你需要：

当首次识别到某个 tool call 的 name 时，为它分配 id，开启一个新的 content block：content_block_start(index:k, content_block:{type:"tool_use", id, name, input:{}})；

后续把 arguments 增量累积为 JSON 片段（OpenAI 是普通字符串流；Anthropic 期望把 input 作为对象，你可以在收齐一个字段后更新，或在 content_block_stop 前一次性填充）；

本轮包含任意 tool_use，最终 message_delta.delta.stop_reason 必须是 "tool_use"；随后 message_stop。

Anthropic 对 tool_use 的输入在流中是 input_json_delta 这种局部 JSON 串的理念；你只要保证结果对象在 content_block_stop 之前成形即可。
Anthropic

用量增量：可在 message_delta 里不断累计 usage.output_tokens，与最终的 stop_reason 一并给出。
Anthropic

错误中断：OpenAI 流中途失败时，把错误转成 event: error，数据形如 {"type":"error","error":{...}} 发出即可。Anthropic 明确支持在流里发送错误事件。
Anthropic

6) 非流式响应回译（OpenAI → Anthropic）
基本骨架：

type:"message"，role:"assistant"；

content = 数组。若仅有文本，把 OpenAI 的 message.content 转成一个 {"type":"text","text":...}。
Anthropic

工具调用：

若 OpenAI 返回了 tool_calls[]，则为每个工具调用在 content[] 里追加一个 {"type":"tool_use","id","name","input":<parsed JSON>}；设置 stop_reason:"tool_use"。
Anthropic

停止原因映射（若用 Chat Completions）：

choices[].finish_reason == "stop" → stop_reason:"end_turn"；

"length" → "max_tokens"；

存在 tool_calls（不论 finish_reason）→ "tool_use"；

OpenAI 的内容过滤结束可近似映射为 "refusal"（Anthropic 文档列为可能值，尤其在流式拒绝场景）。
Anthropic

用量：

OpenAI usage.prompt_tokens/completion_tokens → Anthropic usage.input_tokens/output_tokens。
Anthropic

7) 错误与配额头映射
非流式：OpenAI 出错返回 {"error":{message,type,param,code}}。你应返回 Anthropic 错误形状：顶层 {"type":"error","error":{type,message}}，HTTP 状态码对应 400/401/403/404/413/429/500/529 语义。
Anthropic

流式：把错误以 event:error 事件发出（见第 5 节）。
Anthropic

速率限制与 request-id：可以把 OpenAI 的 x-request-id 透传/映射为 Anthropic 的 request-id 响应头，以便前端调试（Anthropic强调每个响应都有 request-id）。
Anthropic

8) 多模态细节（再次强调）
Anthropic 的 image 块只说明 source（base64/媒体类型/数据）。你要在 OpenAI 侧按chat.completions 的 vision 输入组织为 user 消息里的 content[]，元素是：

文本：{type:"text", text:...}；

图片：{type:"image_url", image_url:{url:"https://... 或 data:..."}}。

注意：system/assistant/tool 角色消息不要带图片（OpenAI 会报错）。
Microsoft Learn
OpenAI Community

9) 边角与兼容性差异（你应当明确处理/忽略）
top_k：忽略。
Anthropic

thinking（扩展思维）：OpenAI 不暴露思维内容；若前端传入，直接忽略即可。
Anthropic

stop_sequences 命中时：把 Anthropic 的 stop_reason:"stop_sequence" 与具体 stop_sequence 一并返回。
Anthropic

tool_result 的 content 可能是字符串或结构化对象；OpenAI role:"tool" 的 content 建议统一转为字符串（必要时 JSON.stringify），避免 schema 不匹配。
Anthropic

并行工具：Anthropic 允许“并行/串行”的提示；OpenAI 也可能一次返回多个 tool_calls，请在映射表里为每个调用分配独立 id 并顺次发回对应的 role:"tool" 消息。
OpenAI Platform

如果你改用 Responses API：

创建请求顶层字段与事件名不同（例如 response.output_text.delta 等）；同样可映射为 Anthropic 的 content_block_delta。

字段 max_output_tokens、工具事件名与输出结构不同；总体实现思路一致。
OpenAI Platform
+1

10) 最后验收清单（逐项自测）
system 已正确“上浮”为首条 system 消息；没有把它误放到 Anthropic messages 里。
Anthropic

tool_use ↔ tool_calls 与 tool_result ↔ role:"tool" 的双向一一映射与顺序严格正确，且 tool_call_id 完整。
Portkey

文本/图片混排顺序在 OpenAI user.content[] 中保持一致；image_url 对象格式合法。
Microsoft Learn

stop_sequences 命中时，返回 stop_reason:"stop_sequence" 与具体 stop_sequence。
Anthropic

流式：事件序列严格为 message_start → 多组 content_block_* → message_delta → message_stop；OpenAI 的 [DONE] 映射为末尾 message_stop。工具参数在 content_block_stop 前完成对象化。
Anthropic

用量：prompt_tokens/completion_tokens ↔ input_tokens/output_tokens。
Anthropic

错误：非流式走 Anthropic 错误 JSON 形状；流式发送 event:error。状态码与消息符合 Anthropic 文档。
Anthropic